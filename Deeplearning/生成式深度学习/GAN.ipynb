{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 生成式对抗网络   Generative Adverasrial Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. 配置GPU 导入相关的库"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "from tensorflow.compat.v1 import ConfigProto, Session\n",
    "config = ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "set_session(Session(config=config))"
   ]
  },
  {
   "source": [
    "## 2. Generator  共计 62w个参数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 32768)             1081344   \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 32768)             0         \n_________________________________________________________________\nreshape (Reshape)            (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 16, 16, 256)       819456    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n=================================================================\nTotal params: 6,264,579\nTrainable params: 6,264,579\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 32     # 潜在可能性空间\n",
    "height = 32         # 图片尺寸\n",
    "width = 32          # 图片尺寸\n",
    "channels = 3        # 图片的通道数\n",
    "\n",
    "generator_input = keras.Input(shape=(latent_dim,))\n",
    "# 类似于解码器\n",
    "# 每层的激活函数采用LeakyReLU 相比于ReLU LeakReLU在输入为负数也有激活 缓解梯度的稀疏性\n",
    "x = layers.Dense(128*16*16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Reshape((16, 16, 128))(x)    # 重新塑性成 14x14x128 的数组 128个特征图\n",
    "x = layers.Conv2D(256, (5, 5), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, (4, 4), padding='same', strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "# 在此上采样为（28, 28, 256）的特征图\n",
    "\n",
    "x = layers.Conv2D(256, (5, 5), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, (5, 5), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(channels, (7, 7), activation='tanh', padding='same')(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "source": [
    "## 3. Discriminator 判别器  共计8w 参数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 790,913\nTrainable params: 790,913\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = keras.Input(shape=(height, width, channels))\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3))(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (4, 4), strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (4, 4), strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(128, (4, 4), strides=(2, 2))(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "discriminator_optimizer = optimizers.RMSprop(\n",
    "    lr = 0.0008,\n",
    "    decay = 1e-8,\n",
    "    clipvalue = 1.0\n",
    ")\n",
    "\n",
    "discriminator.compile(\n",
    "    optimizer = discriminator_optimizer,\n",
    "    loss = 'binary_crossentropy'\n",
    ")"
   ]
  },
  {
   "source": [
    "## 4. 生成对抗网络 Generative Adverasrial Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\nmodel (Functional)           (None, 32, 32, 3)         6264579   \n_________________________________________________________________\nmodel_1 (Functional)         (None, 1)                 790913    \n=================================================================\nTotal params: 7,055,492\nTrainable params: 6,264,579\nNon-trainable params: 790,913\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False     # 判别器不允许训练\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = optimizers.RMSprop(\n",
    "    lr = 0.0004,\n",
    "    decay = 1e-8,\n",
    "    clipvalue = 1.0\n",
    ")\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "source": [
    "## 5. 开始训练GAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "discriminator at loss: 0.7008483409881592\n",
      "adversarial at loss: 0.6835333704948425\n",
      "discriminator at loss: 0.7034196853637695\n",
      "adversarial at loss: 0.8704048991203308\n",
      "discriminator at loss: 0.6908178925514221\n",
      "adversarial at loss: 0.74298095703125\n",
      "discriminator at loss: 0.689926028251648\n",
      "adversarial at loss: 0.7600042819976807\n",
      "discriminator at loss: 0.7033820152282715\n",
      "adversarial at loss: 0.7470231056213379\n",
      "discriminator at loss: 0.690680980682373\n",
      "adversarial at loss: 0.7627683877944946\n",
      "discriminator at loss: 0.6979295015335083\n",
      "adversarial at loss: 0.7489864826202393\n",
      "discriminator at loss: 0.7015222311019897\n",
      "adversarial at loss: 0.7528306245803833\n",
      "discriminator at loss: 0.6934388875961304\n",
      "adversarial at loss: 0.7811828851699829\n",
      "discriminator at loss: 0.6890732049942017\n",
      "adversarial at loss: 0.7545453310012817\n",
      "discriminator at loss: 0.7043299674987793\n",
      "adversarial at loss: 0.7566009759902954\n",
      "discriminator at loss: 0.6918659210205078\n",
      "adversarial at loss: 0.7675271034240723\n",
      "discriminator at loss: 0.6969724893569946\n",
      "adversarial at loss: 0.7273069024085999\n",
      "discriminator at loss: 0.6977392435073853\n",
      "adversarial at loss: 0.7452325820922852\n",
      "discriminator at loss: 0.6890528202056885\n",
      "adversarial at loss: 0.7543631792068481\n",
      "discriminator at loss: 0.6954934597015381\n",
      "adversarial at loss: 0.7576635479927063\n",
      "discriminator at loss: 0.6985330581665039\n",
      "adversarial at loss: 0.7303897142410278\n",
      "discriminator at loss: 0.6955215930938721\n",
      "adversarial at loss: 0.747133195400238\n",
      "discriminator at loss: 0.7183061838150024\n",
      "adversarial at loss: 0.7411770820617676\n",
      "discriminator at loss: 0.688652753829956\n",
      "adversarial at loss: 0.7589211463928223\n",
      "discriminator at loss: 0.7143436074256897\n",
      "adversarial at loss: 0.7282220721244812\n",
      "discriminator at loss: 0.6896849870681763\n",
      "adversarial at loss: 0.7427523136138916\n",
      "discriminator at loss: 0.7835088968276978\n",
      "adversarial at loss: 0.7621160745620728\n",
      "discriminator at loss: 0.6912199258804321\n",
      "adversarial at loss: 0.7434564232826233\n",
      "discriminator at loss: 0.6895672082901001\n",
      "adversarial at loss: 0.7585117220878601\n",
      "discriminator at loss: 0.6912962794303894\n",
      "adversarial at loss: 0.7494508028030396\n",
      "discriminator at loss: 0.705361008644104\n",
      "adversarial at loss: 0.7601827383041382\n",
      "discriminator at loss: 0.6892702579498291\n",
      "adversarial at loss: 0.7317540645599365\n",
      "discriminator at loss: 0.6998699307441711\n",
      "adversarial at loss: 0.763457715511322\n",
      "discriminator at loss: 0.6994857788085938\n",
      "adversarial at loss: 0.725689172744751\n",
      "discriminator at loss: 0.719051718711853\n",
      "adversarial at loss: 0.7503306865692139\n",
      "discriminator at loss: 0.6912338733673096\n",
      "adversarial at loss: 0.7504048347473145\n",
      "discriminator at loss: 0.6920723915100098\n",
      "adversarial at loss: 0.7474868297576904\n",
      "discriminator at loss: 0.6962550282478333\n",
      "adversarial at loss: 0.7579319477081299\n",
      "discriminator at loss: 0.6931031346321106\n",
      "adversarial at loss: 0.7305557131767273\n",
      "discriminator at loss: 0.7161290645599365\n",
      "adversarial at loss: 0.7547990083694458\n",
      "discriminator at loss: 0.686667799949646\n",
      "adversarial at loss: 0.769058346748352\n",
      "discriminator at loss: 0.6950743198394775\n",
      "adversarial at loss: 0.7455434203147888\n",
      "discriminator at loss: 0.6950832605361938\n",
      "adversarial at loss: 0.7379814386367798\n",
      "discriminator at loss: 0.6983963847160339\n",
      "adversarial at loss: 0.7521160244941711\n",
      "discriminator at loss: 0.6927093267440796\n",
      "adversarial at loss: 0.7557899951934814\n",
      "discriminator at loss: 0.6943098902702332\n",
      "adversarial at loss: 0.7409428358078003\n",
      "discriminator at loss: 0.7026537656784058\n",
      "adversarial at loss: 0.7475090026855469\n",
      "discriminator at loss: 0.6952701807022095\n",
      "adversarial at loss: 0.7529972791671753\n",
      "discriminator at loss: 0.6957290172576904\n",
      "adversarial at loss: 0.7521398663520813\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train[y_train.flatten() == 6]\n",
    "x_train = x_train.reshape(\n",
    "    (x_train.shape[0],)+(height, width, channels)).astype('float32') / 255.\n",
    "iterations = 10000\n",
    "batch_size = 32\n",
    "save_dir = '/home/oneran/GAN_pictures/forg'\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vector = np.random.normal(size=(batch_size, latent_dim))\n",
    "    \n",
    "    generated_image = generator.predict(random_latent_vector)\n",
    "\n",
    "    stop = start + batch_size\n",
    "    real_image = x_train[start: stop]\n",
    "\n",
    "    combined_images = np.concatenate([generated_image, real_image], axis=0)\n",
    "\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(size=labels.shape)\n",
    "\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    \n",
    "    random_latent_vector = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "    misleading_labels = np.zeros(shape=(batch_size, 1))\n",
    "\n",
    "    a_loss = gan.train_on_batch(random_latent_vector, misleading_labels)\n",
    "    \n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "\n",
    "        print('discriminator at loss:', d_loss)\n",
    "        print('adversarial at loss:', a_loss)\n",
    "\n",
    "        img = image.array_to_img(generated_image[0]*255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_'+str(step)+'.png'))\n",
    "\n",
    "        img = image.array_to_img(real_image[0]*255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'real_'+str(step)+'.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n_________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 790,913\nTrainable params: 0\nNon-trainable params: 790,913\n_________________________________________________________________\nModel: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 32)]              0         \n_________________________________________________________________\nmodel (Functional)           (None, 32, 32, 3)         6264579   \n_________________________________________________________________\nmodel_1 (Functional)         (None, 1)                 790913    \n=================================================================\nTotal params: 7,055,492\nTrainable params: 6,264,579\nNon-trainable params: 790,913\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}